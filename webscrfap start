from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.select import Select
from bs4 import BeautifulSoup
from datetime import datetime, timedelta
from textblob import TextBlob
import os
import tkinter as tk
from tkinter import simpledialog, messagebox

# Setting up
options = Options()
options.add_argument("--log-level=3")
options.add_argument('--headless')
driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# Thats crazy how you can just get the search topic like this
def getSearchTopic():
    root = tk.Tk()
    root.withdraw() 
    search_topic = simpledialog.askstring("Input", "Enter the stock, CEO, or associated person to look into:")
    root.destroy() 
    return search_topic

searchTopic = getSearchTopic()

# We need to figure out whats revelant 
def extractTimestamps(url):
    driver.get(url)
    search_bar = WebDriverWait(driver, 1).until(
        EC.element_to_be_clickable((By.XPATH, "//input[@class='SearchResultsModule-formInput' and @name='q']"))
    )
    search_bar.send_keys(searchTopic)

    search_button = WebDriverWait(driver, 1).until(
        EC.element_to_be_clickable((By.XPATH, "//button[@class='SearchResultsModule-formButton']"))
    )
    search_button.click()

    select_element = WebDriverWait(driver, 1).until(
        EC.presence_of_element_located((By.XPATH, "//select[@class='Select-input']"))
    )

    select_object = Select(select_element)
    select_object.select_by_value("3")

    html_content = driver.page_source
    soup = BeautifulSoup(html_content, 'html.parser')
    results_element = WebDriverWait(driver, 10).until(
        EC.visibility_of_element_located((By.XPATH, "//span[@class='SearchResultsModule-count-desktop']"))
    )
    print("Search results loaded:", results_element.text)

    # Find all timestamps we need this later
    timestamp_elements = soup.find_all('span', class_='Timestamp-template')
    with open("timestamps.txt", "w", encoding="utf-8") as file:
        for timestamp_element in timestamp_elements:
            timestamp_text = timestamp_element.text.strip()
            file.write(timestamp_text + "\n")

    return timestamp_elements

def filterTimestamps():
    with open("timestamps.txt", "r", encoding="utf-8") as file:
        filteredstamps = file.readlines()

        today = datetime.now()
        week_ago = today - timedelta(days=7)

        filtered_timestamps = []
        for timestamp in filteredstamps:
            timestamp = timestamp.strip()

            # Try different date formats
            date_formats = [
                "%B %d, %Y",  
                "%B %d",     
                "%Y-%m-%d",  
                "%A",       
                "%I %p"     
            ]

            timestamp_date = None
            for date_format in date_formats:
                try:
                    timestamp_date = datetime.strptime(timestamp, date_format)
                    if date_format == "%B %d":
                        timestamp_date = timestamp_date.replace(year=today.year)
                    elif date_format == "%A":
                        if timestamp.lower() == "yesterday":
                            timestamp_date = today - timedelta(days=1)
                    elif date_format == "%I %p":
                        if "hour" in timestamp:
                            hours_ago = int(timestamp.split()[0])
                            timestamp_date = today - timedelta(hours=hours_ago)
                    break
                except ValueError:
                    continue

            if timestamp_date and week_ago <= timestamp_date <= today:
                filtered_timestamps.append(timestamp)

    # Write the filtered timestamps to a new filetrumpo    new_filename = "filtered_timestamps_" + datetime.now().strftime("%Y%m%d%H%M%S") + ".txt"
    new_filename = "filtered_timestamps_" + datetime.now().strftime("%Y%m%d%H%M%S") + ".txt"
    output_path = os.path.join("C:\\Users\\(YOUR NAME HERE PLS)\\Downloads", new_filename)
    with open(output_path, "w", encoding="utf-8") as file:
        for timestamp in filtered_timestamps:
            file.write(timestamp + "\n")

    return filtered_timestamps

def extractTitlesAndDescriptions(driver):
    html_content = driver.page_source
    soup = BeautifulSoup(html_content, 'html.parser')

    titles_and_descriptions = []

    title_elements = soup.find_all('span', class_='PagePromoContentIcons-text')
    description_elements = soup.find_all('div', class_='PagePromo-description')

    for title, description in zip(title_elements, description_elements):
        title_text = title.text.strip()
        description_text = description.text.strip()
        titles_and_descriptions.append((title_text, description_text))

    # Write titles and descriptions to a new file
    new_filename = "titles_descriptions_" + datetime.now().strftime("%Y%m%d%H%M%S") + ".txt"
    output_path = os.path.join("C:\\Users\\(YOUR NAME HERE PLS)\\Downloads", new_filename)
    with open(output_path, "w", encoding="utf-8") as file:
        for title, description in titles_and_descriptions:
            file.write(f"Title: {title}\nDescription: {description}\n\n")
    return titles_and_descriptions

def performSentimentAnalysis(search_topic, titles_and_descriptions):
    total_polarity = 0
    count = 0

    # Calculate total polarity
    for title, description in titles_and_descriptions:
        total_polarity += TextBlob(title).sentiment.polarity + TextBlob(description).sentiment.polarity
        count += 2  # Counting both title and description

    # Calculate average polarity
    avg_polarity = total_polarity / count if count > 0 else 0

    # Determine sentiment message
    sentiment_message = f"Sentiment Analysis for '{search_topic}':\n\n"
    if avg_polarity > 0:
        sentiment_message += "Overall Sentiment: Positive\n"
        sentiment_message += "Advice: The sentiment is positive. This topic has a good reputation. Consider looking into it further."
    else:
        sentiment_message += "Overall Sentiment: Negative\n"
        sentiment_message += "Advice: The sentiment is negative. There might be concerns or risks associated. Proceed with caution."

    root = tk.Tk()
    root.withdraw()  
    messagebox.showinfo("Sentiment Analysis Result", sentiment_message)

def showBigWarningPopup():
    root = tk.Tk()
    root.withdraw()
    messagebox.showwarning(
        "High Risk Warning",
        "DON'T INVEST INTO TRUMP COIN: High volatility and ethical concerns flagged by experts."
    )

# WE DO MAIN NOW GOODLUCK EVERYONE ELSE
url = "https://apnews.com/search?q=#nt=navsearch"
recent_timestamps = extractTimestamps(url)
filtered_timestamps = filterTimestamps()

if filtered_timestamps:
    print("Filtered timestamps within a week:")
    for timestamp in filtered_timestamps:
        print(timestamp)

    titles_and_descriptions = extractTitlesAndDescriptions(driver)
    avg_polarity = performSentimentAnalysis(searchTopic, titles_and_descriptions)
    if avg_polarity is not None and searchTopic.lower() == "trump" and avg_polarity < 0:
        showBigWarningPopup()

    driver.quit()

else:
    print("No timestamps found within a week from the current date.")
    driver.quit()
